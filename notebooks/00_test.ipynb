{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7345d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "ğŸ Python ç‰ˆæœ¬: 3.11.14\n",
      "==============================\n",
      "âœ… æˆåŠŸæ£€æµ‹åˆ° 3 ä¸ª GPU:\n",
      "\n",
      "  - GPU 0: NVIDIA GeForce RTX 5090\n",
      "  - GPU 1: NVIDIA GeForce RTX 5090\n",
      "  - GPU 2: NVIDIA GeForce RTX 5090\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 30)\n",
    "print(f\"ğŸ Python ç‰ˆæœ¬: {sys.version.split()[0]}\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# æ£€æŸ¥ GPU\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"âœ… æˆåŠŸæ£€æµ‹åˆ° {gpu_count} ä¸ª GPU:\\n\")\n",
    "    for i in range(gpu_count):\n",
    "        print(f\"  - GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"âŒ æœªæ£€æµ‹åˆ° GPU (æˆ–è€… PyTorch æœªæ­£ç¡®å®‰è£… CUDA ç‰ˆæœ¬)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2da4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "PyTorch ç‰ˆæœ¬: 2.11.0.dev20251218+cu128\n",
      "CUDA ç‰ˆæœ¬:    12.8\n",
      "========================================\n",
      "\n",
      "âœ… æˆåŠŸï¼RTX 5090 æ­£åœ¨å·¥ä½œï¼\n",
      "   è®¡ç®—è®¾å¤‡: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")  # æœŸæœ›çœ‹åˆ°ç±»ä¼¼ 2.6.0.dev...\n",
    "print(f\"CUDA ç‰ˆæœ¬:    {torch.version.cuda}\") # æœŸæœ›çœ‹åˆ° 12.6\n",
    "print(\"=\"*40)\n",
    "\n",
    "# å®æˆ˜è¿ç®—æµ‹è¯•\n",
    "try:\n",
    "    x = torch.rand(5, 3).to(\"cuda:0\")\n",
    "    y = x @ x.T\n",
    "    print(f\"\\nâœ… æˆåŠŸï¼RTX 5090 æ­£åœ¨å·¥ä½œï¼\")\n",
    "    print(f\"   è®¡ç®—è®¾å¤‡: {y.device}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ä¾ç„¶æŠ¥é”™: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75fa6219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.11.0.dev20251218+cu128\n",
      "CUDA Version (PyTorch): 12.8\n",
      "CUDA Available: True\n",
      "Current Device: NVIDIA GeForce RTX 5090\n",
      "Device Capability: (12, 0)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Version (PyTorch): {torch.version.cuda}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Device Capability: {torch.cuda.get_device_capability(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b40e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported Architectures: ['sm_70', 'sm_75', 'sm_80', 'sm_86', 'sm_90', 'sm_100', 'sm_120']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Supported Architectures:\", torch.cuda.get_arch_list())\n",
    "# You will likely see ['sm_50', 'sm_60', ... 'sm_90', 'sm_100']\n",
    "# If 'sm_120' is missing, that is the root cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce32e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
